justifiedpreviousres=makeProp(nrow(df_gpower[grepl('Previous research', df_gpower$effectsize_justification),]),nrow(df_gpower))
#round(df_gpower[which(df_gpower$typeof_effectsize=='f'),]/nrow(df_gpower)*100,1)
#df_gpower$samplesize_value
# samplesize
samplesizereported=makeCI(sum(!is.na(df_gpower$samplesize_value)),nrow(df_gpower))
samplesizemedian=median(as.numeric(df_gpower[which(!is.na(df_gpower$samplesize_value)),]$samplesize_value))
samplesizeiqr=IQR(as.numeric(df_gpower[which(!is.na(df_gpower$samplesize_value)),]$samplesize_value))
samplesizenumber=paste0(as.character(samplesizemedian),' (', as.character(samplesizeiqr), ')')
# type of test
stattest='' # dummy variable
stattest=makeCI(sum(!is.na(df_gpower$typeof_effectsize)), nrow(df_gpower))
stattestt=round(nrow(df_gpower[grep('T-test',df_gpower$stat_test),])/nrow(df_gpower)*100,2)
stattestanova=round(nrow(df_gpower[grep('ANOVA', df_gpower$stat_test),])/nrow(df_gpower)*100,2)
stattestother=round(nrow(df_gpower[!grepl('T-test|ANOVA|NA',df_gpower$stat_test),])/nrow(df_gpower)*100,2)
#reproducible?
reproducibleoverall=makeCI(nrow(df_gpower[grep('Yes', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
reproduciblewassumptions=round(nrow(df_gpower[grep('make some assumptions', df_gpower$powercalc_reproducible),])/nrow(df_gpower)*100,1)
reproduciblewoassumptions=round(nrow(df_gpower[grep('Yes, based solely on the information in the article or its supplementary material.', df_gpower$powercalc_reproducible),])/nrow(df_gpower)*100,1)
irreproducible=round(nrow(df_gpower[grep('No', df_gpower$powercalc_reproducible),])/nrow(df_gpower)*100,1)
# Multiple comparisons
multiple_comparisons=makeProp(nrow(df_gpower[grep('Yes',df_gpower$multiple_comparisons_powercalc),]), (nrow(df_gpower)-nrow(df_gpower[grep('No, and there is no reason',df_gpower$multiple_comparisons_powercalc),])))
magicmegadf=as.data.frame(rbind(alphareported, alpha005, alphaother,powerreported, power80, power95, powerother, effectsizereported, effectsizef, effectsized, effectsizeother, stattest, stattestanova,stattestt,stattestother,samplesizereported, samplesizenumber, justifiedoverall,justifiedpreviousres,justifiedpilot, reproducibleoverall, reproduciblewassumptions,reproduciblewoassumptions, multiple_comparisons))
rownames(magicmegadf)=c('Alpha (95% CI)','0.05', 'Other level of significance', 'Power (95% CI)', '80%','95%','Other level of power','Effect size (95% CI)', 'd', 'f', 'Other', 'Statistical test (95% CI)', 'ANOVA', 'T-test', 'Other test', 'Sample size reported (95% CI)', 'Sample size median (IQR)', 'Any justification for their effect size (95% CI)', 'Justified: previous research','Justified: own pilot',  'Reproducible (95% CI)','Reproducible with assumptions','Reproducible w/o assumptions', 'Adjusted for multiple comparisons')
magicmegadtable=magicmegadf %>%
kbl(caption = "Reproducibility of power analyses", col.names=c('% Reporting')) %>%
kable_styling(latex_options = "striped")%>%
#kable_classic(full_width = T, html_font = "Cambria")%>%
# redo that stuff...
add_indent(c(2, 3,5,6,7,9,10,11,13,14,15,19,20,22,23)) %>%
add_footnote(c('Note that we have used placeholder variables for the rows statistical tests, these will be replaced with actual data','The sums of percentages may not add up since the numbers are rounded'), notation='symbol')
magicmegadtable
reproduciblewassumptions=makeProp(nrow(df_gpower[grep('make some assumptions', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
reproduciblewoassumptions=makeProp(nrow(df_gpower[grep('Yes, based solely on the information in the article or its supplementary material.', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
df_gpower$stat_test=''
df_gpower$error=''
# Functions to make this a little easier
rounder=function(x){
if (round(x,0)!=100)
{
return(round(x,0))}
else
{return(round(x,1))}}
rounder(99.3)
makeCI <- function(num, denom){
props=prop.test(num,denom)
lower=as.character(rounder(props[['conf.int']][1]*100))
upper=as.character(rounder(props[['conf.int']][2]*100))
CI=paste0(lower,', ',upper)
estimate =as.character(rounder(props[['estimate']]*100))
CInestimate=paste0(estimate,' (',CI,')')
return(CInestimate)
}
makeProp<- function(num, denom){
props=prop.test(num,denom)
estimate =as.character(rounder(props[['estimate']]*100))
return(as.character(estimate))
}
# Alpha
alphareported=makeCI(nrow(df_gpower[which(df_gpower$alpha_reported=='Yes'),]),nrow(df_gpower))
alpha005=makeProp(nrow(df_gpower[which(df_gpower$alpha_value=='0.05'),]),nrow(df_gpower))
alphaother=makeProp(nrow(df_gpower[which(df_gpower$alpha_value!='0.05'),]),nrow(df_gpower))
# Power
powerreported=makeCI(nrow(df_gpower[which(df_gpower$power_reported=='Yes'),]),nrow(df_gpower))
power80=makeProp(nrow(df_gpower[which(df_gpower$power_value==0.8),]),nrow(df_gpower))
power95=makeProp(nrow(df_gpower[which(df_gpower$power_value==0.95),]),nrow(df_gpower))
powerother=makeProp(nrow(df_gpower[which(df_gpower$power_value!=0.8 && df_gpower$power_value!=0.95),]),nrow(df_gpower[which(df_gpower$power_reported=='Yes'),]))
# Effect size
effectsizef=round(nrow(df_gpower[which(df_gpower$typeof_effectsize=='f'),])/nrow(df_gpower)*100,1)
effectsized=round(nrow(df_gpower[which(df_gpower$typeof_effectsize=='d'),])/nrow(df_gpower)*100,1)
effectsizeother=round(nrow(df_gpower[!grepl('f|d',df_gpower$typeof_effectsize),])/nrow(df_gpower)*100,1)
effectsizereported=makeCI(sum(!is.na(df_gpower$typeof_effectsize)),nrow(df_gpower))
# Effect size justification
justifiedoverall=makeCI(nrow(df_gpower[!grepl('No', df_gpower$effectsize_justification),]),nrow(df_gpower))
justifiedpilot=makeProp(nrow(df_gpower[grepl('pilot', df_gpower$effectsize_justification),]),nrow(df_gpower))
justifiedpreviousres=makeProp(nrow(df_gpower[grepl('Previous research', df_gpower$effectsize_justification),]),nrow(df_gpower))
#round(df_gpower[which(df_gpower$typeof_effectsize=='f'),]/nrow(df_gpower)*100,1)
#df_gpower$samplesize_value
# samplesize
samplesizereported=makeCI(sum(!is.na(df_gpower$samplesize_value)),nrow(df_gpower))
samplesizemedian=median(as.numeric(df_gpower[which(!is.na(df_gpower$samplesize_value)),]$samplesize_value))
samplesizeiqr=IQR(as.numeric(df_gpower[which(!is.na(df_gpower$samplesize_value)),]$samplesize_value))
samplesizenumber=paste0(as.character(samplesizemedian),' (', as.character(samplesizeiqr), ')')
# type of test
stattest='' # dummy variable
stattest=makeCI(sum(!is.na(df_gpower$typeof_effectsize)), nrow(df_gpower))
stattestt=round(nrow(df_gpower[grep('T-test',df_gpower$stat_test),])/nrow(df_gpower)*100,2)
stattestanova=round(nrow(df_gpower[grep('ANOVA', df_gpower$stat_test),])/nrow(df_gpower)*100,2)
stattestother=round(nrow(df_gpower[!grepl('T-test|ANOVA|NA',df_gpower$stat_test),])/nrow(df_gpower)*100,2)
#reproducible?
reproducibleoverall=makeCI(nrow(df_gpower[grep('Yes', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
reproduciblewassumptions=makeProp(nrow(df_gpower[grep('make some assumptions', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
reproduciblewoassumptions=makeProp(nrow(df_gpower[grep('Yes, based solely on the information in the article or its supplementary material.', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
# Multiple comparisons
multiple_comparisons=makeProp(nrow(df_gpower[grep('Yes',df_gpower$multiple_comparisons_powercalc),]), (nrow(df_gpower)-nrow(df_gpower[grep('No, and there is no reason',df_gpower$multiple_comparisons_powercalc),])))
magicmegadf=as.data.frame(rbind(alphareported, alpha005, alphaother,powerreported, power80, power95, powerother, effectsizereported, effectsizef, effectsized, effectsizeother, stattest, stattestanova,stattestt,stattestother,samplesizereported, samplesizenumber, justifiedoverall,justifiedpreviousres,justifiedpilot, reproducibleoverall, reproduciblewassumptions,reproduciblewoassumptions, multiple_comparisons))
rownames(magicmegadf)=c('Alpha (95% CI)','0.05', 'Other level of significance', 'Power (95% CI)', '80%','95%','Other level of power','Effect size (95% CI)', 'd', 'f', 'Other', 'Statistical test (95% CI)', 'ANOVA', 'T-test', 'Other test', 'Sample size reported (95% CI)', 'Sample size median (IQR)', 'Any justification for their effect size (95% CI)', 'Justified: previous research','Justified: own pilot',  'Reproducible (95% CI)','Reproducible with assumptions','Reproducible w/o assumptions', 'Adjusted for multiple comparisons')
magicmegadtable=magicmegadf %>%
kbl(caption = "Reproducibility of power analyses", col.names=c('% Reporting')) %>%
kable_styling(latex_options = "striped")%>%
#kable_classic(full_width = T, html_font = "Cambria")%>%
# redo that stuff...
add_indent(c(2, 3,5,6,7,9,10,11,13,14,15,19,20,22,23)) %>%
add_footnote(c('Note that we have used placeholder variables for the rows statistical tests, these will be replaced with actual data','The sums of percentages may not add up since the numbers are rounded'), notation='symbol')
magicmegadtable
magicmegadtable=magicmegadf %>%
kbl(caption = "Table 1. Complete reporting and reproducibility of GPower calculations", col.names=c('% Reporting')) %>%
kable_styling(latex_options = "striped")%>%
#kable_classic(full_width = T, html_font = "Cambria")%>%
# redo that stuff...
add_indent(c(2, 3,5,6,7,9,10,11,13,14,15,19,20,22,23)) %>%
add_footnote(c('Note that we have used placeholder variables for the rows statistical tests, these will be replaced with actual data','The sums of percentages may not add up since the numbers are rounded'), notation='symbol')
magicmegadtable
knitr::kable(table(df_gpower$typeof_powercalc, df_gpower$when_powercalc))
knitr::kable(table(df_gpower$typeof_powercalc, df_gpower$when_powercalc))
knitr::kable(table(df_gpower$typeof_powercalc, df_gpower$when_powercalc))
error=qt(0.975,df=length(na.omit(df_gpower$impact_factor))-1)*sd(df_gpower$impact_factor, na.rm=TRUE)/sqrt(na.omit(length(df_gpower$impact_factor)))
#row_means <- apply(X=data, MARGIN=1, FUN=mean, na.rm=TRUE)
# fix the impact factor shit to solve so that you can have the mean ignoring nans
impact_factor=paste0(round(mean(df_gpower$impact_factor,na.rm=TRUE),1),' (95% CI ',round(mean(df_gpower$impact_factor,na.rm=TRUE)-error,1), ', ',round(mean(df_gpower$impact_factor,na.rm=TRUE)+error,1),')' )
df_gpower[which(df_gpower$typeof_powercalc=='A priori (i.e., solves for sample size)'),])
df_gpower[which(df_gpower$typeof_powercalc=='A priori (i.e., solves for sample size)'),]
nrow(df_gpower[which(df_gpower$typeof_powercalc=='A priori (i.e., solves for sample size)'),])
nrow(df_gpower[which(df_gpower$when_powercalc=='Before running the study'),])
nrow(df_gpower[which(df_gpower$when_powercalc=='Before running the study' && df_gpower[which(df_gpower$typeof_powercalc=='A priori (i.e., solves for sample size)'),])
nrow(df_gpower[which(df_gpower$when_powercalc=='Before running the study' && df_gpower[which(df_gpower$typeof_powercalc=='A priori (i.e., solves for sample size)'),]))
nrow(df_gpower[which(df_gpower$when_powercalc=='Before running the study' && df_gpower$typeof_powercalc=='A priori (i.e., solves for sample size)'),]))
nrow(df_gpower[which(df_gpower$when_powercalc=='Before running the study' && df_gpower$typeof_powercalc=='A priori (i.e., solves for sample size)'),])
nrow(subset(df_gpower, typeof_powercalc == 'A priori (i.e., solves for sample size)' | when_powercalc == 'Before running the study	'))
nrow(subset(df_gpower, typeof_powercalc == 'A priori (i.e., solves for sample size)' && when_powercalc == 'Before running the study	'))
timingdf=table(df_gpower$typeof_powercalc, df_gpower$when_powercalc)
supptable1=knitr::kable(timingdf, caption = "Supplementary Table 1. Type and timing of power calculations", booktabs = T, linesep = "", align = "c") %>%
kable_styling(latex_options = "striped")
st[1,2]
st1[1,2]
# this chunk estimates the total number of published articles that use GPower for doing (1) a power analysis, or (2) an a priori sample size calculation
#fileEncoding variable so that the column headers don't have junk text
ex=read.csv('./queryHits.csv', header=T, fileEncoding="UTF-8-BOM")
# number of articles coded
denom <- nrow(df_gpower_orig)
# number of articles meeting our inclusion criteria
include <- nrow(df_gpower)
# number of articles used for a priori sample size calculations
apriori <- sum(grepl("A priori", df_gpower$typeof_powercalc) & grepl("Before", df_gpower$when_powercalc))
# percentage of PMC articles that were hits
proportion <- ex$pmcHits/ex$pmcTotal
#initialize dataframe for point estimates and confidence intervals
cis <- data.frame(matrix(nrow=6, ncol=3))
# create function to calculate the point estimates and confidence intervals
ciCalc <- function(raw, proportion, num, denom){
cis <- c(raw * proportion * num / denom,
raw * proportion * prop.test(x=num, n=denom, conf.level=.95)$conf.int[1],
raw * proportion * prop.test(x=num, n=denom, conf.level=.95)$conf.int[2]
)
return(cis)
}
# run the function to calculate point estimates and confidence intervals
cis <- rbind(ciCalc(ex$pmcTotal, proportion, include, denom),
ciCalc(ex$pmcTotal, proportion, apriori, denom),
ciCalc(ex$pubmedTotal, proportion, include, denom),
ciCalc(ex$pubmedTotal, proportion, apriori, denom),
ciCalc(ex$dimensionsTotal, proportion, include, denom),
ciCalc(ex$dimensionsTotal, proportion, apriori, denom)
)
# assign row names and column names
rownames(cis) <- c("pmcInclude",
"pmcApriori",
"pubmedInclude",
"pubmedApriori",
"dimensionsInclude",
"dimensionsApriori"
)
colnames(cis) <- c("point",
"ci.lb",
"ci.ub"
)
cis <- cis %>% round(0)
#supplementary table 1
st2 <- cis
rownames(st1) <- c("PubMed Central included",
"PubMed Central a priori",
"PubMed included",
"PubMed, a priori",
"Dimensions included",
"Dimensions a priori"
)
# this chunk estimates the total number of published articles that use GPower for doing (1) a power analysis, or (2) an a priori sample size calculation
#fileEncoding variable so that the column headers don't have junk text
ex=read.csv('./queryHits.csv', header=T, fileEncoding="UTF-8-BOM")
# number of articles coded
denom <- nrow(df_gpower_orig)
# number of articles meeting our inclusion criteria
include <- nrow(df_gpower)
# number of articles used for a priori sample size calculations
apriori <- sum(grepl("A priori", df_gpower$typeof_powercalc) & grepl("Before", df_gpower$when_powercalc))
# percentage of PMC articles that were hits
proportion <- ex$pmcHits/ex$pmcTotal
#initialize dataframe for point estimates and confidence intervals
cis <- data.frame(matrix(nrow=6, ncol=3))
# create function to calculate the point estimates and confidence intervals
ciCalc <- function(raw, proportion, num, denom){
cis <- c(raw * proportion * num / denom,
raw * proportion * prop.test(x=num, n=denom, conf.level=.95)$conf.int[1],
raw * proportion * prop.test(x=num, n=denom, conf.level=.95)$conf.int[2]
)
return(cis)
}
# run the function to calculate point estimates and confidence intervals
cis <- rbind(ciCalc(ex$pmcTotal, proportion, include, denom),
ciCalc(ex$pmcTotal, proportion, apriori, denom),
ciCalc(ex$pubmedTotal, proportion, include, denom),
ciCalc(ex$pubmedTotal, proportion, apriori, denom),
ciCalc(ex$dimensionsTotal, proportion, include, denom),
ciCalc(ex$dimensionsTotal, proportion, apriori, denom)
)
# assign row names and column names
rownames(cis) <- c("pmcInclude",
"pmcApriori",
"pubmedInclude",
"pubmedApriori",
"dimensionsInclude",
"dimensionsApriori"
)
colnames(cis) <- c("point",
"ci.lb",
"ci.ub"
)
cis <- cis %>% round(0)
#supplementary table 1
st2 <- cis
rownames(st2) <- c("PubMed Central included",
"PubMed Central a priori",
"PubMed included",
"PubMed, a priori",
"Dimensions included",
"Dimensions a priori"
)
colnames(st2) <- c("Point estimate",
"95% confidence Interval, lower bound",
"95% confidence Interval, upper bound"
)
st2[1,2]
st2[2,1]
st2[4,2]
minapriori=st2[4,2]
maxapriori=st2[6,3]
minanypowercalc=st2[3,2]
maxanypowercalc=st2[5,3]
minapriori
maxapriori
minanypowercalc
df_gpower[which(df_gpower$powercalc_reproducible)]
nrow(df_gpower[grep('Yes',df_gpower$powercalc_reproducible)])
nrow(df_gpower[grep('Yes',df_gpower$powercalc_reproducible),])
nrow(df_gpower[grep('assumptions',df_gpower$powercalc_reproducible).])
nrow(df_gpower[grep('assumptions',df_gpower$powercalc_reproducible),])
magicmegadtable
options(scipen = 100)
library(readr)
library(tidyverse) # for cleaner code
library(knitr) # for knitting and kable function
library(kableExtra) # for kable table styling
options(scipen = 100)
supptable1
supptable2=knitr::kable(st2, caption = "Supplementary Table 2. Estimates of the number of published articles that use GPower.", booktabs = T, linesep = "", align = "c") %>%
kable_styling(latex_options = "striped") %>%
kable_styling(font_size = 8) %>%
add_footnote(paste0("The total number of article in each database since 2017 is: PubMed Central ", prettyNum(ex$pmcTotal, big.mark=",", scientific=F), "; PubMed ", prettyNum(ex$pubmedTotal, big.mark=",", scientific=F), "; dimensions.ai ", prettyNum(ex$dimensionsTotal, big.mark=",", scientific=F), "."), notation = "symbol", threeparttable = T)
table(df_gpower$powercalc_justification)
View(df_gpower)
table(df_gpower$effectsize_justification)
knitr::kable(table(df_gpower$effectsize_justification))
knitr::kable(table(df_gpower$effectsize_justification)) %>%kable_styling(latex_options = "striped")
knitr::kable(table(df_gpower$effectsize_justification), col.names=c('Type of justification','No. of articles')) %>%kable_styling(latex_options = "striped")
knitr::kable(table(df_gpower$ANOVA_within_between.), col.names=c('ANOVA situation','No. of articles')) %>%kable_styling(latex_options = "striped")
knitr::kable(table(df_gpower$ANOVA_within_between.), col.names=c('Does it adjust for the ANOVA conundrum','No. of articles')) %>%kable_styling(latex_options = "striped")
View(df_gpower)
knitr::kable(table(df_gpower$matching_powercalc_stats), col.names=c('Does the power calculation match the statistical test','No. of articles')) %>%kable_styling(latex_options = "striped")
knitr::kable(table(df_gpower$multiple_comparisons_powercalc), col.names=c('Does it adjust for multiple comparisons?','No. of articles')) %>%kable_styling(latex_options = "striped")
magicmegadtable
knitr::kable(table(df_gpower$effectsize_justification), col.names=c('Type of justification','No. of articles')) %>%kable_styling(latex_options = "striped")
knitr::kable(table(df_gpower$ANOVA_within_between.), col.names=c('Does it adjust for the ANOVA conundrum?','No. of articles')) %>%kable_styling(latex_options = "striped"%>%column_spec(1, width = "10em"))
knitr::kable(table(df_gpower$ANOVA_within_between.), col.names=c('Does it adjust for the ANOVA conundrum?','No. of articles')) %>%
kable_styling(latex_options = "striped"%>%
column_spec(1, width = "10em"))
i=knitr::kable(table(df_gpower$ANOVA_within_between.), col.names=c('Does it adjust for the ANOVA conundrum?','No. of articles')) %>%kable_styling(latex_options = "striped")
i%>%column_spec(1, width = "10em")
i=knitr::kable(table(df_gpower$multiple_comparisons_powercalc), col.names=c('Does it adjust for multiple comparisons?','No. of articles')) %>%kable_styling(latex_options = "striped")
i%>%column_spec(1, width = "13em")
i=knitr::kable(table(df_gpower$matching_powercalc_stats), col.names=c('Does the power calculation match the statistical test?','No. of articles')) %>%kable_styling(latex_options = "striped")
i%>%column_spec(1, width = "13em")
i
i
i=knitr::kable(table(df_gpower$effectsize_justification), col.names=c('Type of justification','No. of articles'), caption='Supplementary Table 4. Justification of effect size') %>%kable_styling(latex_options = "striped",latex_options = c("hold_position"))
i=knitr::kable(table(df_gpower$effectsize_justification), col.names=c('Type of justification','No. of articles'), caption='Supplementary Table 4. Justification of effect size') %>%kable_styling(latex_options = "striped")%>%kable_styling(latex_options = c("hold_position"))
i
supptable1
supptable2=knitr::kable(st2, caption = "Supplementary Table 2. Estimates of the number of published articles that use GPower.", booktabs = T, linesep = "", align = "c") %>%
kable_styling(latex_options = "striped")%>%kable_styling(latex_options = c("hold_position")) %>%
kable_styling(font_size = 8) %>%
add_footnote(paste0("The total number of article in each database since 2017 is: PubMed Central ", prettyNum(ex$pmcTotal, big.mark=",", scientific=F), "; PubMed ", prettyNum(ex$pubmedTotal, big.mark=",", scientific=F), "; dimensions.ai ", prettyNum(ex$dimensionsTotal, big.mark=",", scientific=F), "."), notation = "symbol", threeparttable = T)
library(readr)
library(tidyverse) # for cleaner code
library(knitr) # for knitting and kable function
library(kableExtra) # for kable table styling
options(scipen = 100)
# go in and delete the first row from the gpower form, and the third row that are meta-data and irrelevant to our dataframe
# remove every column up to reviewer initial (since IP and exact location is revealed :-) )
df_gpower_orig=read.csv('./gpower_pilotData.csv')
df_gpower_orig=df_gpower_orig[which(df_gpower_orig$reviewer=='EZ'),]
#remove the ineligibile
df_gpower=df_gpower_orig[which(df_gpower_orig$include=='Include'),]
# check
dfs=read.csv('pmc_result.txt',col.names='PMCID')
lista=as.list(dfs$PMCID)
set.seed(1453)
samples=sample(lista,15)
searchstring=paste(unlist(samples),collapse=" OR ")
pmidsearch<-file("pmcidsearch_general.txt")
writeLines(searchstring, pmidsearch)
close(pmidsearch)
p = 0.5
moe = 0.2
alpha=0.05
z=qnorm(p=alpha, lower.tail=TRUE)*-1
# this chunk estimates the total number of published articles that use GPower for doing (1) a power analysis, or (2) an a priori sample size calculation
#fileEncoding variable so that the column headers don't have junk text
ex=read.csv('./queryHits.csv', header=T, fileEncoding="UTF-8-BOM")
# number of articles coded
denom <- nrow(df_gpower_orig)
# number of articles meeting our inclusion criteria
include <- nrow(df_gpower)
# number of articles used for a priori sample size calculations
apriori <- sum(grepl("A priori", df_gpower$typeof_powercalc) & grepl("Before", df_gpower$when_powercalc))
# percentage of PMC articles that were hits
proportion <- ex$pmcHits/ex$pmcTotal
#initialize dataframe for point estimates and confidence intervals
cis <- data.frame(matrix(nrow=6, ncol=3))
# create function to calculate the point estimates and confidence intervals
ciCalc <- function(raw, proportion, num, denom){
cis <- c(raw * proportion * num / denom,
raw * proportion * prop.test(x=num, n=denom, conf.level=.95)$conf.int[1],
raw * proportion * prop.test(x=num, n=denom, conf.level=.95)$conf.int[2]
)
return(cis)
}
# run the function to calculate point estimates and confidence intervals
cis <- rbind(ciCalc(ex$pmcTotal, proportion, include, denom),
ciCalc(ex$pmcTotal, proportion, apriori, denom),
ciCalc(ex$pubmedTotal, proportion, include, denom),
ciCalc(ex$pubmedTotal, proportion, apriori, denom),
ciCalc(ex$dimensionsTotal, proportion, include, denom),
ciCalc(ex$dimensionsTotal, proportion, apriori, denom)
)
# assign row names and column names
rownames(cis) <- c("pmcInclude",
"pmcApriori",
"pubmedInclude",
"pubmedApriori",
"dimensionsInclude",
"dimensionsApriori"
)
colnames(cis) <- c("point",
"ci.lb",
"ci.ub"
)
cis <- cis %>% round(0)
#supplementary table 1
st2 <- cis
rownames(st2) <- c("PubMed Central included",
"PubMed Central a priori",
"PubMed included",
"PubMed, a priori",
"Dimensions included",
"Dimensions a priori"
)
colnames(st2) <- c("Point estimate",
"95% confidence Interval, lower bound",
"95% confidence Interval, upper bound"
)
minapriori=st2[4,2]
maxapriori=st2[6,3]
minanypowercalc=st2[3,2]
maxanypowercalc=st2[5,3]
timingdf=table(df_gpower$typeof_powercalc, df_gpower$when_powercalc)
supptable1=knitr::kable(timingdf, caption = "Supplementary Table 1. Type and timing of power calculations", booktabs = T, linesep = "", align = "c") %>%
kable_styling(latex_options = "striped")%>%kable_styling(latex_options = c("hold_position"))
df_gpower$stat_test=''
df_gpower$error=''
# Functions to make this a little easier
rounder=function(x){
if (round(x,0)!=100)
{
return(round(x,0))}
else
{return(round(x,1))}}
rounder(99.3)
makeCI <- function(num, denom){
props=prop.test(num,denom)
lower=as.character(rounder(props[['conf.int']][1]*100))
upper=as.character(rounder(props[['conf.int']][2]*100))
CI=paste0(lower,', ',upper)
estimate =as.character(rounder(props[['estimate']]*100))
CInestimate=paste0(estimate,' (',CI,')')
return(CInestimate)
}
makeProp<- function(num, denom){
props=prop.test(num,denom)
estimate =as.character(rounder(props[['estimate']]*100))
return(as.character(estimate))
}
# Alpha
alphareported=makeCI(nrow(df_gpower[which(df_gpower$alpha_reported=='Yes'),]),nrow(df_gpower))
alpha005=makeProp(nrow(df_gpower[which(df_gpower$alpha_value=='0.05'),]),nrow(df_gpower))
alphaother=makeProp(nrow(df_gpower[which(df_gpower$alpha_value!='0.05'),]),nrow(df_gpower))
# Power
powerreported=makeCI(nrow(df_gpower[which(df_gpower$power_reported=='Yes'),]),nrow(df_gpower))
power80=makeProp(nrow(df_gpower[which(df_gpower$power_value==0.8),]),nrow(df_gpower))
power95=makeProp(nrow(df_gpower[which(df_gpower$power_value==0.95),]),nrow(df_gpower))
powerother=makeProp(nrow(df_gpower[which(df_gpower$power_value!=0.8 && df_gpower$power_value!=0.95),]),nrow(df_gpower[which(df_gpower$power_reported=='Yes'),]))
# Effect size
effectsizef=round(nrow(df_gpower[which(df_gpower$typeof_effectsize=='f'),])/nrow(df_gpower)*100,1)
effectsized=round(nrow(df_gpower[which(df_gpower$typeof_effectsize=='d'),])/nrow(df_gpower)*100,1)
effectsizeother=round(nrow(df_gpower[!grepl('f|d',df_gpower$typeof_effectsize),])/nrow(df_gpower)*100,1)
effectsizereported=makeCI(sum(!is.na(df_gpower$typeof_effectsize)),nrow(df_gpower))
# Effect size justification
justifiedoverall=makeCI(nrow(df_gpower[!grepl('No', df_gpower$effectsize_justification),]),nrow(df_gpower))
justifiedpilot=makeProp(nrow(df_gpower[grepl('pilot', df_gpower$effectsize_justification),]),nrow(df_gpower))
justifiedpreviousres=makeProp(nrow(df_gpower[grepl('Previous research', df_gpower$effectsize_justification),]),nrow(df_gpower))
#round(df_gpower[which(df_gpower$typeof_effectsize=='f'),]/nrow(df_gpower)*100,1)
#df_gpower$samplesize_value
# samplesize
samplesizereported=makeCI(sum(!is.na(df_gpower$samplesize_value)),nrow(df_gpower))
samplesizemedian=median(as.numeric(df_gpower[which(!is.na(df_gpower$samplesize_value)),]$samplesize_value))
samplesizeiqr=IQR(as.numeric(df_gpower[which(!is.na(df_gpower$samplesize_value)),]$samplesize_value))
samplesizenumber=paste0(as.character(samplesizemedian),' (', as.character(samplesizeiqr), ')')
# type of test
stattest='' # dummy variable
stattest=makeCI(sum(!is.na(df_gpower$typeof_effectsize)), nrow(df_gpower))
stattestt=round(nrow(df_gpower[grep('T-test',df_gpower$stat_test),])/nrow(df_gpower)*100,2)
stattestanova=round(nrow(df_gpower[grep('ANOVA', df_gpower$stat_test),])/nrow(df_gpower)*100,2)
stattestother=round(nrow(df_gpower[!grepl('T-test|ANOVA|NA',df_gpower$stat_test),])/nrow(df_gpower)*100,2)
#reproducible?
reproducibleoverall=makeCI(nrow(df_gpower[grep('Yes', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
reproduciblewassumptions=makeProp(nrow(df_gpower[grep('make some assumptions', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
reproduciblewoassumptions=makeProp(nrow(df_gpower[grep('Yes, based solely on the information in the article or its supplementary material.', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
# Multiple comparisons
multiple_comparisons=makeProp(nrow(df_gpower[grep('Yes',df_gpower$multiple_comparisons_powercalc),]), (nrow(df_gpower)-nrow(df_gpower[grep('No, and there is no reason',df_gpower$multiple_comparisons_powercalc),])))
magicmegadf=as.data.frame(rbind(alphareported, alpha005, alphaother,powerreported, power80, power95, powerother, effectsizereported, effectsizef, effectsized, effectsizeother, stattest, stattestanova,stattestt,stattestother,samplesizereported, samplesizenumber, justifiedoverall,justifiedpreviousres,justifiedpilot, reproducibleoverall, reproduciblewassumptions,reproduciblewoassumptions, multiple_comparisons))
rownames(magicmegadf)=c('Alpha (95% CI)','0.05', 'Other level of significance', 'Power (95% CI)', '80%','95%','Other level of power','Effect size (95% CI)', 'd', 'f', 'Other', 'Statistical test (95% CI)', 'ANOVA', 'T-test', 'Other test', 'Sample size reported (95% CI)', 'Sample size median (IQR)', 'Any justification for their effect size (95% CI)', 'Justified: previous research','Justified: own pilot',  'Reproducible (95% CI)','Reproducible with assumptions','Reproducible w/o assumptions', 'Adjusted for multiple comparisons')
df_gpower$stat_test=''
df_gpower$error=''
# Functions to make this a little easier
rounder=function(x){
if (round(x,0)!=100)
{
return(round(x,0))}
else
{return(round(x,1))}}
rounder(99.3)
makeCI <- function(num, denom){
props=prop.test(num,denom)
lower=as.character(rounder(props[['conf.int']][1]*100))
upper=as.character(rounder(props[['conf.int']][2]*100))
CI=paste0(lower,', ',upper)
estimate =as.character(rounder(props[['estimate']]*100))
CInestimate=paste0(estimate,' (',CI,')')
return(CInestimate)
}
makeProp<- function(num, denom){
props=prop.test(num,denom)
estimate =as.character(rounder(props[['estimate']]*100))
return(as.character(estimate))
}
# Alpha
alphareported=makeCI(nrow(df_gpower[which(df_gpower$alpha_reported=='Yes'),]),nrow(df_gpower))
alpha005=makeProp(nrow(df_gpower[which(df_gpower$alpha_value=='0.05'),]),nrow(df_gpower))
alphaother=makeProp(nrow(df_gpower[which(df_gpower$alpha_value!='0.05'),]),nrow(df_gpower))
# Power
powerreported=makeCI(nrow(df_gpower[which(df_gpower$power_reported=='Yes'),]),nrow(df_gpower))
power80=makeProp(nrow(df_gpower[which(df_gpower$power_value==0.8),]),nrow(df_gpower))
power95=makeProp(nrow(df_gpower[which(df_gpower$power_value==0.95),]),nrow(df_gpower))
powerother=makeProp(nrow(df_gpower[which(df_gpower$power_value!=0.8 && df_gpower$power_value!=0.95),]),nrow(df_gpower[which(df_gpower$power_reported=='Yes'),]))
# Effect size
effectsizef=round(nrow(df_gpower[which(df_gpower$typeof_effectsize=='f'),])/nrow(df_gpower)*100,1)
effectsized=round(nrow(df_gpower[which(df_gpower$typeof_effectsize=='d'),])/nrow(df_gpower)*100,1)
effectsizeother=round(nrow(df_gpower[!grepl('f|d',df_gpower$typeof_effectsize),])/nrow(df_gpower)*100,1)
effectsizereported=makeCI(sum(!is.na(df_gpower$typeof_effectsize)),nrow(df_gpower))
# Effect size justification
justifiedoverall=makeCI(nrow(df_gpower[!grepl('No', df_gpower$effectsize_justification),]),nrow(df_gpower))
justifiedpilot=makeProp(nrow(df_gpower[grepl('pilot', df_gpower$effectsize_justification),]),nrow(df_gpower))
justifiedpreviousres=makeProp(nrow(df_gpower[grepl('Previous research', df_gpower$effectsize_justification),]),nrow(df_gpower))
#round(df_gpower[which(df_gpower$typeof_effectsize=='f'),]/nrow(df_gpower)*100,1)
#df_gpower$samplesize_value
# samplesize
samplesizereported=makeCI(sum(!is.na(df_gpower$samplesize_value)),nrow(df_gpower))
samplesizemedian=median(as.numeric(df_gpower[which(!is.na(df_gpower$samplesize_value)),]$samplesize_value))
samplesizeiqr=IQR(as.numeric(df_gpower[which(!is.na(df_gpower$samplesize_value)),]$samplesize_value))
samplesizenumber=paste0(as.character(samplesizemedian),' (', as.character(samplesizeiqr), ')')
# type of test
stattest='' # dummy variable
stattest=makeCI(sum(!is.na(df_gpower$typeof_effectsize)), nrow(df_gpower))
stattestt=round(nrow(df_gpower[grep('T-test',df_gpower$stat_test),])/nrow(df_gpower)*100,2)
stattestanova=round(nrow(df_gpower[grep('ANOVA', df_gpower$stat_test),])/nrow(df_gpower)*100,2)
stattestother=round(nrow(df_gpower[!grepl('T-test|ANOVA|NA',df_gpower$stat_test),])/nrow(df_gpower)*100,2)
#reproducible?
reproducibleoverall=makeCI(nrow(df_gpower[grep('Yes', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
reproduciblewassumptions=makeProp(nrow(df_gpower[grep('make some assumptions', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
reproduciblewoassumptions=makeProp(nrow(df_gpower[grep('Yes, based solely on the information in the article or its supplementary material.', df_gpower$powercalc_reproducible),]),nrow(df_gpower))
# Multiple comparisons
multiple_comparisons=makeProp(nrow(df_gpower[grep('Yes',df_gpower$multiple_comparisons_powercalc),]), (nrow(df_gpower)-nrow(df_gpower[grep('No, and there is no reason',df_gpower$multiple_comparisons_powercalc),])))
magicmegadf=as.data.frame(rbind(alphareported, alpha005, alphaother,powerreported, power80, power95, powerother, effectsizereported, effectsizef, effectsized, effectsizeother, stattest, stattestanova,stattestt,stattestother,samplesizereported, samplesizenumber, justifiedoverall,justifiedpreviousres,justifiedpilot, reproducibleoverall, reproduciblewassumptions,reproduciblewoassumptions, multiple_comparisons))
rownames(magicmegadf)=c('Alpha (95% CI)','0.05', 'Other level of significance', 'Power (95% CI)', '80%','95%','Other level of power','Effect size (95% CI)', 'd', 'f', 'Other', 'Statistical test (95% CI)', 'ANOVA', 'T-test', 'Other test', 'Sample size reported (95% CI)', 'Sample size median (IQR)', 'Any justification for their effect size (95% CI)', 'Justified: previous research','Justified: own pilot',  'Reproducible (95% CI)','Reproducible with assumptions','Reproducible w/o assumptions', 'Adjusted for multiple comparisons')
